server:
  port: 6660
  tomcat:
    accept-count: 1000
    max-threads: 500
    #dispater-Servlet
#  servlet:
#    path: /
  servlet:
# bug:看起来是layui的js和spring的modelAndView无法识别contextPath
    context-path: /crmCustomer
spring:
  application:
    name: customer-service
    #====================redis==========================解决中文乱码
  http:
    encoding:
      force: true

#====================redis==========================
  redis:
    database: 0
    #单机配置
    host:
    port: 6379
    password:
    pool:
      max-active: 500
      max-idle: 50
      min-idle: 1

    #----自定义参数-----start
    cache:
      #缓存使用redis 1号库(如果mybatis二级缓存也启用了，也同样用1号库)
      database: 1
    #用于开启redis来作为mybatis的二级缓存
    mybatis:
      cache:
      #不建议使用mybatis二级缓存
        enable: false
    #----自定义参数----end

    #哨兵优先
    sentinel:
      master: mymaster
      nodes: 172.16.8.87:26379,172.16.8.86:26379,172.16.8.88:26379
    cluster:
      nodes: #172.16.200.35:6379,172.16.200.36:6379,172.16.200.37:6379,172.16.200.38:6379,172.16.200.39:6379,172.16.200.40:6379
#  cache:
#    cache-names: customer,customerPhone
#    type: redis
  output:
    ansi:
      enabled: always
#====================thymeleaf==================
  thymeleaf:
    cache: false
#=====================database 连接池=================
  datasource:
    url:  ${jdbc.url}
    driverClassName: oracle.jdbc.OracleDriver
    username: ${jdbc.username}
#    password: mydbacloudcall
    password: ${jdbc.password}
    type: com.alibaba.druid.pool.DruidDataSource
    # 初始化大小，最小，最大
    initialSize: 1
    minIdle: 3
    #最大连接池数量
    maxActive: 300
    #获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，
    #如果需要可以通过配置useUnfairLock属性为true使用非公平锁
    maxWait: 60000
    #配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒（3600000:为1小时）,目前550秒，即9分钟多
    timeBetweenEvictionRunsMillis: 550000
    # 配置一个连接在池中最小生存的时间，单位是毫秒(300000:为5分钟)
    minEvictableIdleTimeMillis: 300000
    #用来检测连接是否有效的sql，要求是一个查询语句。
    #如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。
    validationQuery: ${jdbc.validationQuery}
    #申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。建议配置为true，不影响性能，并且保证安全性
    testWhileIdle: true
    #申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。缺省值:true
    testOnBorrow: false
    #归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。缺省值:false
    testOnReturn: false
    #打开PSCache，并且指定每个连接上PSCache的大小
    #是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql5.5以下的版本中没有PSCache功能，建议关闭掉。5.5及以上版本有PSCache，建议开启。缺省值:false
    poolPreparedStatements: true
    #要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100。
    maxPoolPreparedStatementPerConnectionSize: 100
    #配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
    filters: stat,wall,slf4j,config
    #通过connectProperties属性来打开mergeSql功能；慢SQL记录
#    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000;config.decrypt=true;config.decrypt.key=${jdbc.publicKey}
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    #合并多个DruidDataSource的监控数据
    useGlobalDataSourceStat: true
  data:
    elasticsearch:
#      cluster-name: hfcrm
#      cluster-nodes: 172.16.200.31:9300,172.16.200.32:9300,172.16.200.33:9300
      cluster-name: zylog-cluster
      cluster-nodes: 172.16.8.42:9300,172.16.8.43:9300,172.16.8.44:9300,172.16.8.45:9300,172.16.8.46:9300
#      cluster-nodes: 172.16.8.42:9300,172.16.8.43:9300,172.16.8.44:9300,172.16.8.45:9300,172.16.8.46:9300,172.16.8.100:9300,172.16.8.101:9300,172.16.8.104:9300,172.16.8.107:9300,172.16.8.111:9300
#      properties:
  session:
    store-type: redis
#============== kafka ===================
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 172.16.8.181:9092,172.16.8.182:9092,172.16.8.183:9092
#    bootstrap-servers: 172.16.200.31:9092,172.16.200.32:9092,172.16.200.33:9092
    producer:
#      retries: 1
      # 每次批量发送消息的数量
#      batch-size: 16384
      #32M
#      buffer-memory: 33554432
      acks: -1
#      transaction-id-prefix: kafka-transaction-
#      client-id: crmProducer
    consumer:
      # 指定默认消费者group id
      group-id: hfcrm
      auto-offset-reset: earliest
      #如果想消息不丢失，最好关闭自动提交位移, 在消息被完整处理之后再手动提交位移
      enable-auto-commit: false
      #默认500
      max-poll-records: 50
#      不能配：InstanceAlreadyExistsException
#      client-id: crmConsumer
    listener:
      concurrency: 3
      ack-mode: manual
#      client-id: crmListener
#  jpa:
#    hibernate:
#      ddl-auto: update
#      naming:
#        strategy: org.hibernate.cfg.ImprovedNamingStrategy
#    show-sql: true
#    database: mysql
# ====================自定义jdbc属性====================
#jdbc:
#  driverClassName: com.mysql.jdbc.Driver
#  url: jdbc:mysql://172.16.8.84:3306/hfcrm?useUnicode=true&characterEncoding=utf-8&allowMultiQueries=true&useSSL=true
#  username: cloudcall
#  passwordOrigin: mydbacloudcall
#  password: bfcLpJMx58TZXtkwyDR0ioLJr1cdtMmALX/ux63ZPNmYYHKMZ+VJh80D4FiDePHWqCbTOkKPyMZriq2aolnr4A==
#  publicKey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAOCsG7OaL5TYoz2ENjPxi6kXVBdYxQxZ7zpyhKAqfZy0DmTUWJQi2GpA9rqxxv9FhZJQzRmWcUWv3vbLb8f6v4sCAwEAAQ==
#  validationQuery: select current_timestamp()

jdbc:
  driverClassName: oracle.jdbc.OracleDriver
  url: jdbc:oracle:thin:@172.16.8.167:1521:gddev
  username: mydba2
  password: mydbagddev890
  validationQuery: select 1 from dual
druidAdmin:
  loginUsername: druid
  loginPassword: winsnlife

#logging:
#  config: classpath:logback-dev.xml
#security:
#  user:
#    name: wws
#    password: 1

#====================log4j2==========================
#elasticsearch:
#  setting:
#    indexName: hfcrm_${spring.profiles.active}
#    useServerConfiguration: false
#    shards: 5
#    replicas: 1
#    refreshInterval:  1s
#    indexStoreType: fs
